{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "47f0d4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from datasets import load_dataset, DatasetDict\n",
    "from transformers import (\n",
    "    AutoTokenizer,\n",
    "    AutoModelForSequenceClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding,\n",
    "    pipeline\n",
    ")\n",
    "import evaluate\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a7b35dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (120000, 2)\n",
      "Testing data shape: (7600, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Wall St. Bears Claw Back Into the Black (Reute...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Carlyle Looks Toward Commercial Aerospace (Reu...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Oil and Economy Cloud Stocks' Outlook (Reuters...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Iraq Halts Oil Exports from Main Southern Pipe...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Oil prices soar to all-time record, posing new...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Wall St. Bears Claw Back Into the Black (Reute...      2\n",
       "1  Carlyle Looks Toward Commercial Aerospace (Reu...      2\n",
       "2  Oil and Economy Cloud Stocks' Outlook (Reuters...      2\n",
       "3  Iraq Halts Oil Exports from Main Southern Pipe...      2\n",
       "4  Oil prices soar to all-time record, posing new...      2"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load AG News dataset (train & test splits)\n",
    "dataset = load_dataset(\"ag_news\")\n",
    "\n",
    "# Convert train split to pandas DataFrame\n",
    "train_df = pd.DataFrame(dataset[\"train\"])\n",
    "test_df = pd.DataFrame(dataset[\"test\"])\n",
    "\n",
    "# Save to CSV files\n",
    "train_df.to_csv(\"ag_news_train.csv\", index=False)\n",
    "test_df.to_csv(\"ag_news_test.csv\", index=False)\n",
    "\n",
    "print(\"Training data shape:\", train_df.shape)\n",
    "print(\"Testing data shape:\", test_df.shape)\n",
    "\n",
    "# Show first few rows\n",
    "train_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c7ad2387",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 120000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 7600\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Tokenization function\n",
    "def tokenize_function(example):\n",
    "    return tokenizer(example[\"text\"], truncation=True, padding=\"max_length\", max_length=128)\n",
    "\n",
    "# Apply tokenization on train & test datasets\n",
    "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "# Keep only useful columns\n",
    "tokenized_datasets = tokenized_datasets.remove_columns([\"text\"])\n",
    "tokenized_datasets = tokenized_datasets.rename_column(\"label\", \"labels\")\n",
    "tokenized_datasets.set_format(\"torch\")\n",
    "\n",
    "tokenized_datasets\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9990b713",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model and optimizer setup complete!\n",
      "Model device: cuda:0\n",
      "Number of parameters: 109,485,316\n"
     ]
    }
   ],
   "source": [
    "# Manual training approach - bypassing Trainer issues\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim import AdamW\n",
    "from tqdm.auto import tqdm\n",
    "import os\n",
    "\n",
    "# Check and set up GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Load BERT model for sequence classification (4 classes in AG News)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=4,\n",
    "    attention_probs_dropout_prob=0.1,\n",
    "    hidden_dropout_prob=0.1\n",
    ")\n",
    "\n",
    "# Move model to GPU if available\n",
    "model = model.to(device)\n",
    "\n",
    "# Set up optimizer and scheduler\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(\"./bert-news-classifier\", exist_ok=True)\n",
    "os.makedirs(\"./logs\", exist_ok=True)\n",
    "\n",
    "print(\"Model and optimizer setup complete!\")\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "print(f\"Number of parameters: {sum(p.numel() for p in model.parameters()):,}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a0fe0db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (4.56.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (3.18.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.34.0 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.35.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2025.9.18)\n",
      "Requirement already satisfied: requests in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.22.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (0.6.2)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (2025.3.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from huggingface-hub<1.0,>=0.34.0->transformers) (4.13.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\haram\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->transformers) (2025.4.26)\n"
     ]
    }
   ],
   "source": [
    "! pip install -U transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dc857443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "GPU: NVIDIA GeForce RTX 4050 Laptop GPU\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Core imports\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# Mixed precision for GPU efficiency\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "# Device setup\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device:\", device)\n",
    "if device.type == \"cuda\":\n",
    "    print(\"GPU:\", torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7cfb859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training samples: 120000\n",
      "Evaluation samples: 7600\n",
      "Training batches: 30000\n",
      "Evaluation batches: 1900\n"
     ]
    }
   ],
   "source": [
    "# Shuffle + prepare datasets\n",
    "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42)   # ~120k samples\n",
    "eval_dataset = tokenized_datasets[\"test\"]                      # ~7.6k samples\n",
    "\n",
    "# Use smaller batch size to save GPU\n",
    "batch_size = 4  \n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    eval_dataset, batch_size=batch_size, shuffle=False,\n",
    "    num_workers=2, pin_memory=True, persistent_workers=True\n",
    ")\n",
    "\n",
    "print(f\"Training samples: {len(train_dataset)}\")\n",
    "print(f\"Evaluation samples: {len(eval_dataset)}\")\n",
    "print(f\"Training batches: {len(train_dataloader)}\")\n",
    "print(f\"Evaluation batches: {len(eval_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ad6f5efa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haram\\AppData\\Local\\Temp\\ipykernel_17748\\2875473871.py:8: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n"
     ]
    }
   ],
   "source": [
    "# Move model to device\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "# Mixed precision scaler\n",
    "scaler = GradScaler()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e14a8ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f6f43ea530442e3bf37cbb4cac3cfcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training Epoch 1:   0%|          | 0/30000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Haram\\AppData\\Local\\Temp\\ipykernel_17748\\1990460365.py:21: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 2\n",
    "gradient_accumulation_steps = 4  # simulate larger batch size\n",
    "\n",
    "total_steps = 0\n",
    "best_eval_loss = float(\"inf\")\n",
    "\n",
    "print(\"Starting training...\")\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
    "    \n",
    "    # Training phase\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    \n",
    "    progress_bar = tqdm(train_dataloader, desc=f\"Training Epoch {epoch + 1}\")\n",
    "    \n",
    "    for step, batch in enumerate(progress_bar):\n",
    "        batch = {k: v.to(device) for k, v in batch.items()}\n",
    "        \n",
    "        with autocast():\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss / gradient_accumulation_steps  # scale loss\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "        \n",
    "        if (step + 1) % gradient_accumulation_steps == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "        total_steps += 1\n",
    "        \n",
    "        progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    avg_train_loss = total_loss / len(train_dataloader)\n",
    "    print(f\"Average training loss: {avg_train_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b82e6324",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Successfully saved model artifacts to 'bert_news_classifier.pkl'\n",
      "File size: 1283.89 MB\n",
      "\n",
      "Saved objects:\n",
      "  - model_state_dict\n",
      "  - optimizer_state_dict\n",
      "  - tokenizer\n",
      "  - dataset\n",
      "  - tokenized_datasets\n",
      "  - device\n",
      "  - num_epochs\n",
      "  - batch_size\n",
      "  - best_eval_loss\n",
      "  - model_config\n",
      "  - train_df\n",
      "  - test_df\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "# Create a dictionary with all important objects\n",
    "model_artifacts = {\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'tokenizer': tokenizer,\n",
    "    'dataset': dataset,\n",
    "    'tokenized_datasets': tokenized_datasets,\n",
    "    'device': str(device),\n",
    "    'num_epochs': num_epochs,\n",
    "    'batch_size': batch_size,\n",
    "    'best_eval_loss': best_eval_loss,\n",
    "    'model_config': model.config,\n",
    "    'train_df': train_df,\n",
    "    'test_df': test_df\n",
    "}\n",
    "\n",
    "# Save to pickle file\n",
    "pickle_filename = 'bert_news_classifier.pkl'\n",
    "with open(pickle_filename, 'wb') as f:\n",
    "    pickle.dump(model_artifacts, f)\n",
    "\n",
    "print(f\"✓ Successfully saved model artifacts to '{pickle_filename}'\")\n",
    "print(f\"File size: {os.path.getsize(pickle_filename) / (1024**2):.2f} MB\")\n",
    "print(\"\\nSaved objects:\")\n",
    "for key in model_artifacts.keys():\n",
    "    print(f\"  - {key}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e3496447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading pickle file...\n",
      "✓ Pickle file loaded successfully!\n",
      "\n",
      "Loaded objects:\n",
      "  - model_state_dict\n",
      "  - optimizer_state_dict\n",
      "  - tokenizer\n",
      "  - dataset\n",
      "  - tokenized_datasets\n",
      "  - device\n",
      "  - num_epochs\n",
      "  - batch_size\n",
      "  - best_eval_loss\n",
      "  - model_config\n",
      "  - train_df\n",
      "  - test_df\n",
      "\n",
      "============================================================\n",
      "Recreating model from saved state...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Model loaded and moved to cuda\n",
      "\n",
      "============================================================\n",
      "TESTING THE MODEL\n",
      "============================================================\n",
      "\n",
      "--- Test Sample 1 ---\n",
      "Input: Apple unveils new iPhone with advanced AI capabilities and improved camera syste...\n",
      "Predicted Category: Sci/Tech\n",
      "Confidence: 98.83%\n",
      "All probabilities: {'World': 0.0013335935, 'Sports': 0.00017650673, 'Business': 0.010206983, 'Sci/Tech': 0.988283}\n",
      "\n",
      "--- Test Sample 2 ---\n",
      "Input: Manchester United defeats Barcelona 3-1 in Champions League final match....\n",
      "Predicted Category: Sports\n",
      "Confidence: 51.10%\n",
      "All probabilities: {'World': 0.48177612, 'Sports': 0.5110066, 'Business': 0.004407131, 'Sci/Tech': 0.0028101597}\n",
      "\n",
      "--- Test Sample 3 ---\n",
      "Input: Stock market reaches all-time high as tech companies report strong earnings....\n",
      "Predicted Category: Sci/Tech\n",
      "Confidence: 66.36%\n",
      "All probabilities: {'World': 0.029234715, 'Sports': 0.00078330067, 'Business': 0.30638018, 'Sci/Tech': 0.66360176}\n",
      "\n",
      "--- Test Sample 4 ---\n",
      "Input: NASA discovers evidence of water on Mars, raising hopes for future colonization....\n",
      "Predicted Category: Sci/Tech\n",
      "Confidence: 94.08%\n",
      "All probabilities: {'World': 0.05738984, 'Sports': 0.00041583608, 'Business': 0.001421461, 'Sci/Tech': 0.94077283}\n",
      "\n",
      "============================================================\n",
      "✓ Testing completed successfully!\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "# Load the pickle file\n",
    "pickle_path = r'C:\\Users\\Haram\\Downloads\\bert_news_classifier.pkl'\n",
    "\n",
    "print(\"Loading pickle file...\")\n",
    "with open(pickle_path, 'rb') as f:\n",
    "    loaded_artifacts = pickle.load(f)\n",
    "\n",
    "print(\"✓ Pickle file loaded successfully!\\n\")\n",
    "\n",
    "# Display what was loaded\n",
    "print(\"Loaded objects:\")\n",
    "for key in loaded_artifacts.keys():\n",
    "    print(f\"  - {key}\")\n",
    "\n",
    "# Recreate the model\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"Recreating model from saved state...\")\n",
    "loaded_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\", \n",
    "    num_labels=4\n",
    ")\n",
    "loaded_model.load_state_dict(loaded_artifacts['model_state_dict'])\n",
    "loaded_model.eval()\n",
    "\n",
    "# Move to appropriate device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loaded_model.to(device)\n",
    "print(f\"✓ Model loaded and moved to {device}\")\n",
    "\n",
    "# Get tokenizer from pickle\n",
    "loaded_tokenizer = loaded_artifacts['tokenizer']\n",
    "\n",
    "# AG News label mapping\n",
    "label_map = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\", \n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"TESTING THE MODEL\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test samples - one from each category\n",
    "test_samples = [\n",
    "    \"Apple unveils new iPhone with advanced AI capabilities and improved camera system.\",\n",
    "    \"Manchester United defeats Barcelona 3-1 in Champions League final match.\",\n",
    "    \"Stock market reaches all-time high as tech companies report strong earnings.\",\n",
    "    \"NASA discovers evidence of water on Mars, raising hopes for future colonization.\"\n",
    "]\n",
    "\n",
    "for i, text in enumerate(test_samples, 1):\n",
    "    print(f\"\\n--- Test Sample {i} ---\")\n",
    "    print(f\"Input: {text[:80]}...\")\n",
    "    \n",
    "    # Tokenize input\n",
    "    inputs = loaded_tokenizer(text, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Get prediction\n",
    "    with torch.no_grad():\n",
    "        outputs = loaded_model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        probabilities = torch.nn.functional.softmax(logits, dim=-1)\n",
    "        predicted_class = torch.argmax(logits, dim=-1).item()\n",
    "        confidence = probabilities[0][predicted_class].item()\n",
    "    \n",
    "    print(f\"Predicted Category: {label_map[predicted_class]}\")\n",
    "    print(f\"Confidence: {confidence:.2%}\")\n",
    "    print(f\"All probabilities: {dict(zip(label_map.values(), probabilities[0].cpu().numpy()))}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓ Testing completed successfully!\")\n",
    "print(\"=\"*60)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a73970a9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
